{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module(body=[FunctionDef(name='add', args=arguments(posonlyargs=[], args=[], kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Assign(targets=[Name(id='out', ctx=Store())], value=BinOp(left=Constant(value=1), op=Add(), right=Constant(value=1))), Return(value=Name(id='out', ctx=Load()))], decorator_list=[Call(func=Name(id='jit', ctx=Load()), args=[], keywords=[keyword(arg='target', value=Constant(value='cpu'))])])], type_ignores=[])\n",
      "Visit Module\n",
      "Visit FunctionDef\n",
      "Visit Assign\n",
      "Visit Name\n",
      "Visit BinOp\n",
      "Visit Constant\n",
      "Visit Constant\n",
      "Visit Return\n",
      "Visit Name\n",
      "# from tvm.script import ir as I\n",
      "# from tvm.script import relax as R\n",
      "\n",
      "@I.ir_module\n",
      "class Module:\n",
      "    @R.function\n",
      "    def add() -> R.Tensor((), dtype=\"int32\"):\n",
      "        gv: R.Tensor((), dtype=\"int32\") = R.const(1, \"int32\")\n",
      "        gv1: R.Tensor((), dtype=\"int32\") = R.const(1, \"int32\")\n",
      "        out: R.Tensor((), dtype=\"int32\") = R.add(gv, gv1)\n",
      "        return out\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "import ast\n",
    "from typing import Dict, Any\n",
    "import tvm\n",
    "from tvm import relax as rx\n",
    "from tvm.script import relax as R\n",
    "from tvm.script.ir_builder import relax as relax_builder, ir as I, IRBuilder as IB\n",
    "def jit(target=\"cpu\"):\n",
    "    assert target in [\"cpu\", \"gpu\"]\n",
    "    def inner(fn):\n",
    "        return JIT(fn, target=target)\n",
    "    return inner\n",
    "\n",
    "class JIT:\n",
    "    def __init__(self, fn, target=\"cpu\"):\n",
    "        self.fn = fn\n",
    "        self.target = target\n",
    "    \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        fn_src = inspect.getsource(self.fn)\n",
    "        fn_ast = ast.parse(fn_src)\n",
    "        print(ast.dump(fn_ast))\n",
    "        code_generator = CodeGenerator(fn_ast, self.target)\n",
    "        compiled_kernel = code_generator.code_gen()\n",
    "        return compiled_kernel()\n",
    "\n",
    "class CodeGenerator(ast.NodeVisitor):\n",
    "    def __init__(self, fn_ast, target):\n",
    "        self.fn_ast = fn_ast\n",
    "        self.target = target\n",
    "        self.ib = IB()\n",
    "        self.ir_module = None\n",
    "        self.entry = None\n",
    "        self.ret = None\n",
    "        self.local_var_table : Dict[str, Any] = {}\n",
    "    \n",
    "    def code_gen(self):\n",
    "        with self.ib:\n",
    "            self.visit(self.fn_ast)\n",
    "        module = self.ib.get()\n",
    "        print(module)\n",
    "        mapped_target = {'cpu': 'llvm', 'gpu': 'cuda'}\n",
    "        target = tvm.target.Target(mapped_target[self.target])\n",
    "        with tvm.transform.PassContext(opt_level=3):\n",
    "            ex = rx.build(module, target=target) # ex is a excutable obj\n",
    "        device = tvm.cuda() if \"cuda\" in target.keys else tvm.cpu()\n",
    "        vm = rx.VirtualMachine(ex, device=device)\n",
    "        return vm[self.entry]\n",
    "\n",
    "\n",
    "    def visit(self, node):\n",
    "        print(\"Visit \" + node.__class__.__name__)\n",
    "        return super().visit(node)\n",
    "    \n",
    "    def visit_Module(self, node: ast.Module):\n",
    "        if self.ir_module:\n",
    "            raise AssertionError(\"We should have only one module!\")\n",
    "        self.ir_module = I.ir_module()\n",
    "        with self.ir_module:\n",
    "            super().generic_visit(node)\n",
    "        \n",
    "    \n",
    "    def visit_FunctionDef(self, node: ast.FunctionDef):\n",
    "        fn = relax_builder.function()\n",
    "        self.entry = node.name\n",
    "        with fn:\n",
    "            R.func_name(node.name)\n",
    "            self._visit_compound_stmt(node.body)\n",
    "\n",
    "            if self.ret is None:\n",
    "                R.func_ret_value(rx.ShapeExpr([]))\n",
    "            else:\n",
    "                R.func_ret_value(self.ret)\n",
    "    \n",
    "    def visit_Pass(self, node: ast.Pass):\n",
    "        pass\n",
    "\n",
    "    def visit_Assign(self, node: ast.Assign):\n",
    "        if len(node.targets) != 1:\n",
    "            raise NotImplementedError(\"Doesn't support simultaneous multiple assignment like 'a = b = c' in AST node type: {}\".format(type(node).__name__))\n",
    "        target: rx.Var = self.visit(node.targets[0])\n",
    "        value = self.visit(node.value)\n",
    "        self.local_var_table[target.name_hint] = value\n",
    "        self.ib.name(target.name_hint, value)\n",
    "    \n",
    "    def visit_Name(self, node: ast.Name):\n",
    "        name = node.id\n",
    "        if isinstance(node.ctx, ast.Store):\n",
    "            if name not in self.local_var_table.keys():\n",
    "                self.local_var_table[name] = rx.Var(name, struct_info=rx.ObjectStructInfo())\n",
    "        return self.local_var_table[name]\n",
    "    \n",
    "    def visit_BinOp(self, node: ast.BinOp):\n",
    "        lhs = self.visit(node.left)\n",
    "        rhs = self.visit(node.right)\n",
    "        return R.emit(self._binOp_maker(node.op)(lhs, rhs))\n",
    "    \n",
    "    def visit_Return(self, node: ast.Return):\n",
    "        ret_value = self.visit(node.value)\n",
    "        return ret_value\n",
    "    \n",
    "    def visit_Constant(self, node: ast.Constant):\n",
    "        return R.emit(rx.const(node.value))\n",
    "        \n",
    "    def _visit_compound_stmt(self, stmts):\n",
    "        assert isinstance(stmts, (list, tuple))\n",
    "        for stmt in stmts:\n",
    "            ret = self.visit(stmt)\n",
    "            if ret is not None and isinstance(stmt, ast.Return):\n",
    "                self.ret = ret\n",
    "    \n",
    "    def _binOp_maker(self, node: ast.operator):\n",
    "        if isinstance(node, ast.Add):\n",
    "            return R.add\n",
    "        else:\n",
    "            raise NotImplementedError(\"Unsupported AST node type: {}\".format(type(node).__name__))\n",
    "    \n",
    "    def generic_visit(self, node: ast.AST):\n",
    "        raise NotImplementedError(\"Unsupported AST node type: {}\".format(type(node).__name__))\n",
    "\n",
    "\n",
    "@jit(target=\"cpu\")\n",
    "def add():\n",
    "    out = 1 + 1\n",
    "    return out\n",
    "\n",
    "print(add())  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyscf_isdf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
